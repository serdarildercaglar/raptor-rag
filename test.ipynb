{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34725123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 16:32:51,328 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT41SummarizationModel object at 0x7c26aa758910>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7c26aa7588b0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-07-13 16:32:51,328 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT41SummarizationModel object at 0x7c26aa758910>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7c26aa7588b0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-07-13 16:32:51,329 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: VLLM\n",
      "            Embedding Model: <raptor.EmbeddingModels.VLLMEmbeddingModel object at 0x7c28041d6d10>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2025-07-13 16:32:51,329 - Async support: True, Batch support: True\n",
      "2025-07-13 16:32:51,329 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT41SummarizationModel object at 0x7c26aa758910>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7c26aa7588b0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: VLLM\n",
      "            Embedding Model: <raptor.EmbeddingModels.VLLMEmbeddingModel object at 0x7c28041d6d10>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-07-13 16:32:51,331 - Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7c2804241450>\n",
      "2025-07-13 16:32:51,332 - Using collapsed_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tree loaded: 65 nodes, 1 layers\n",
      "ğŸ“Š Available embedding keys: ['VLLM']\n",
      "\n",
      "ğŸ“ Query: Bu dokÃ¼manÄ±n ana konusu nedir?\n",
      "ğŸ“„ Result: Bu metin, \"ZULFICORE SYSTEM\" adlÄ± bir projenin tanÄ±tÄ±mÄ±nÄ± ve yazarÄ±n bu konudaki dÃ¼ÅŸÃ¼ncelerini anlatÄ±yor. Yazar, bu devrimi baÅŸlatmaya karar verdiÄŸini ve hedefinin dÃ¼nyada tek bir Ã§ocuÄŸun bile aÃ§ kalmamasÄ± olduÄŸunu ifade ediyor. 18 yaÅŸÄ±nda AtatÃ¼rkâ€™Ã¼ tanÄ±ma gÃ¶revi ile ilk adÄ±mÄ±nÄ± attÄ±ÄŸÄ±nÄ± ve bu sÃ¼reÃ§te birÃ§ok tarihi figÃ¼rden (Hz.\n",
      "\n",
      "Bu metin, insan iliÅŸkileri, toplumdaki eÅŸitlik, Ã§ocuklarÄ±n saÄŸlÄ±ÄŸÄ± ve mutluluÄŸu Ã¼zerine derin dÃ¼ÅŸÃ¼nceleri iÃ§ermektedir. Yazar, arkadaÅŸlarÄ±yla birlikte hayallerini gerÃ§ekleÅŸtirdiÄŸi anlarda %97 oranÄ±nda mutlu olduÄŸunu belirtirken, biyolojik Ã§ocuÄŸunun ve babasÄ±nÄ±n yanÄ±ndayken hissettiÄŸi duygularÄ± da dile getiriyor. Allahâ€™Ä±n kendisine bir kÄ±z Ã§ocuÄŸu vermemesi Ã¼zerinden kÄ±z Ã§ocuklarÄ±nÄ±n Ã¶nemine\n",
      "\n",
      "Bu metin, derin bir iÃ§sel dÃ¼ÅŸÃ¼nce ve geniÅŸ bir vizyonla yazÄ±lmÄ±ÅŸ bir kitabÄ±n Ã¶zeti olarak gÃ¶rÃ¼lÃ¼yor. Yazar, ilahi kudretin sÄ±rlarÄ±na, bilinÃ§ ve yaÅŸamÄ±n anlamÄ±na dair derin sorgulamalar yapÄ±yor. \"AlgÄ±lanabilir boyutta hiÃ§ bir ÅŸey yok\" ifadesiyle, varlÄ±k Ã¼zerine bir eleÅŸtiri getiriyor. \"Olay ufku\" kavramÄ±yla, bilinmeyene dair bir ipucu bÄ±rakÄ±ld\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# RAPTOR Retrieve - Ultra Simple\n",
    "import pickle\n",
    "\n",
    "# Load tree directly\n",
    "tree_path = \"raptor_tree.pkl\" \n",
    "with open(tree_path, 'rb') as f:\n",
    "    tree = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… Tree loaded: {len(tree.all_nodes)} nodes, {tree.num_layers} layers\")\n",
    "\n",
    "# Check what embedding keys exist\n",
    "sample_node = list(tree.all_nodes.values())[0]\n",
    "embedding_keys = list(sample_node.embeddings.keys())\n",
    "print(f\"ğŸ“Š Available embedding keys: {embedding_keys}\")\n",
    "\n",
    "# Load RAPTOR with correct embedding key\n",
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig, VLLMEmbeddingModel\n",
    "\n",
    "embedding_model = VLLMEmbeddingModel(base_url=\"http://localhost:8008\")\n",
    "\n",
    "# Use the first available embedding key from tree\n",
    "embedding_key = embedding_keys[0]\n",
    "\n",
    "config = RetrievalAugmentationConfig(\n",
    "    tr_context_embedding_model=embedding_key,  # Use key from tree\n",
    "    tr_embedding_model=embedding_model\n",
    ")\n",
    "\n",
    "RA = RetrievalAugmentation(config=config, tree=tree)\n",
    "\n",
    "# Test query\n",
    "query = \"Bu dokÃ¼manÄ±n ana konusu nedir?\"\n",
    "prefixed_query = f\"query: {query}\"\n",
    "\n",
    "print(f\"\\nğŸ“ Query: {query}\")\n",
    "result = await RA.retrieve_async(prefixed_query, top_k=5, max_tokens=300)\n",
    "print(f\"ğŸ“„ Result: {result[:3000]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
