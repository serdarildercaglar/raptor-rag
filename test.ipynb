{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34725123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 16:37:45,683 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT41SummarizationModel object at 0x7c26a9f13eb0>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7c26a9f134f0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-07-13 16:37:45,684 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT41SummarizationModel object at 0x7c26a9f13eb0>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7c26a9f134f0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-07-13 16:37:45,684 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: VLLM\n",
      "            Embedding Model: <__main__.VLLMQueryEmbedding object at 0x7c26a9f12980>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2025-07-13 16:37:45,685 - Async support: True, Batch support: True\n",
      "2025-07-13 16:37:45,685 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <raptor.SummarizationModels.GPT41SummarizationModel object at 0x7c26a9f13eb0>\n",
      "            Embedding Models: {'OpenAI': <raptor.EmbeddingModels.OpenAIEmbeddingModel object at 0x7c26a9f134f0>}\n",
      "            Cluster Embedding Model: OpenAI\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'o200k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: VLLM\n",
      "            Embedding Model: <__main__.VLLMQueryEmbedding object at 0x7c26a9f12980>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-07-13 16:37:45,685 - Using collapsed_tree\n",
      "2025-07-13 16:37:45,731 - Using collapsed_tree\n",
      "2025-07-13 16:37:45,759 - Using collapsed_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running RAPTOR retrieve test...\n",
      "✅ Tree loaded: 65 nodes, 1 layers\n",
      "\n",
      "==================================================\n",
      "🔍 RAPTOR RETRIEVAL TEST\n",
      "==================================================\n",
      "\n",
      "📝 Query: Bu dokümanın ana konusu nedir?\n",
      "----------------------------------------\n",
      "📄 Result (1072 chars):\n",
      "Bu metin, \"ZULFICORE SYSTEM\" adlı bir projenin tanıtımını ve yazarın bu konudaki düşüncelerini anlatıyor. Yazar, bu devrimi başlatmaya karar verdiğini ve hedefinin dünyada tek bir çocuğun bile aç kalmaması olduğunu ifade ediyor. 18 yaşında Atatürk’ü ...\n",
      "\n",
      "📝 Query: En önemli bilgiler nelerdir?\n",
      "----------------------------------------\n",
      "📄 Result (884 chars):\n",
      "Özet:  Bu metin, çeşitli peygamberlerin kıssalarını ve Zulficore yorumunu ele alarak, mucizelerin ve sessiz yankıların kaynağını ifade ediyor.   1. **Hz. İsa – Mucizelerin Kaynağı:** Maide Suresi 110. ayette, Allah, Hz. İsa'ya ve annesine verilen nim...\n",
      "\n",
      "📝 Query: What is the main topic?\n",
      "----------------------------------------\n",
      "📄 Result (889 chars):\n",
      "I write to you not merely as a technology entrepreneur, but with deep respect for someone who has truly succeeded in uniting science with kindness Your work—especially App Inventor and your commitment to open knowledge—has brought hope to millions  Y...\n",
      "\n",
      "✅ Retrieval test completed!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "RAPTOR Retrieve - Works in both terminal and Jupyter\n",
    "\"\"\"\n",
    "import asyncio\n",
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig\n",
    "import requests\n",
    "from raptor import BaseEmbeddingModel\n",
    "\n",
    "class VLLMQueryEmbedding(BaseEmbeddingModel):\n",
    "    \"\"\"VLLM embedding for queries with 'query:' prefix\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = \"http://localhost:8008\"):\n",
    "        self.base_url = base_url\n",
    "        \n",
    "    def create_embedding(self, text: str):\n",
    "        # Always use query prefix for retrieval\n",
    "        payload = {\n",
    "            \"input\": [f\"query: {text}\"],\n",
    "            \"model\": \"intfloat/multilingual-e5-large\"\n",
    "        }\n",
    "        \n",
    "        response = requests.post(f\"{self.base_url}/v1/embeddings\", json=payload, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['data'][0]['embedding']\n",
    "        else:\n",
    "            raise Exception(f\"VLLM error: {response.status_code}\")\n",
    "\n",
    "# =============================================================================\n",
    "# JUPYTER KULLANIMI: Aşağıdaki satırı kopyala/yapıştır\n",
    "# await retrieve_test()\n",
    "# =============================================================================\n",
    "\n",
    "async def retrieve_test():\n",
    "    \"\"\"Main retrieval test - USE THIS IN JUPYTER\"\"\"\n",
    "    \n",
    "    tree_path = \"raptor_tree.pkl\"\n",
    "    \n",
    "    # Query embedding model (with query: prefix)\n",
    "    query_embedding_model = VLLMQueryEmbedding()\n",
    "    \n",
    "    # Config for retrieval (must match tree's embedding key)\n",
    "    config = RetrievalAugmentationConfig(\n",
    "        tr_embedding_model=query_embedding_model,\n",
    "        tr_context_embedding_model=\"VLLM\",  # Key from tree\n",
    "        tr_top_k=5,\n",
    "        tr_selection_mode=\"top_k\"\n",
    "    )\n",
    "    \n",
    "    # Load RAPTOR with tree\n",
    "    RA = RetrievalAugmentation(config=config, tree=tree_path)\n",
    "    \n",
    "    print(f\"✅ Tree loaded: {len(RA.tree.all_nodes)} nodes, {RA.tree.num_layers} layers\")\n",
    "    \n",
    "    # Test queries\n",
    "    queries = [\n",
    "        \"Bu dokümanın ana konusu nedir?\",\n",
    "        \"En önemli bilgiler nelerdir?\",\n",
    "        \"What is the main topic?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🔍 RAPTOR RETRIEVAL TEST\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n📝 Query: {query}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Use async retrieve\n",
    "        result = await RA.retrieve_async(\n",
    "            query,              # Direct query (query: prefix automatic)\n",
    "            top_k=3,           # Top 3 nodes\n",
    "            max_tokens=300,    # Max response length\n",
    "            collapse_tree=True # Search all layers\n",
    "        )\n",
    "        \n",
    "        print(f\"📄 Result ({len(result)} chars):\")\n",
    "        print(result[:250] + \"...\" if len(result) > 250 else result)\n",
    "    \n",
    "    print(\"\\n✅ Retrieval test completed!\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Terminal version only\"\"\"\n",
    "    print(\"🚀 Running RAPTOR retrieve test...\")\n",
    "    asyncio.run(retrieve_test())\n",
    "\n",
    "# For direct use in Jupyter\n",
    "async def jupyter_test():\n",
    "    \"\"\"Simple single query test\"\"\"\n",
    "    tree_path = \"raptor_tree.pkl\" \n",
    "    query_embedding_model = VLLMQueryEmbedding()\n",
    "    \n",
    "    config = RetrievalAugmentationConfig(\n",
    "        tr_embedding_model=query_embedding_model,\n",
    "        tr_context_embedding_model=\"VLLM\"\n",
    "    )\n",
    "    \n",
    "    RA = RetrievalAugmentation(config=config, tree=tree_path)\n",
    "    print(f\"✅ Tree loaded: {len(RA.tree.all_nodes)} nodes\")\n",
    "    \n",
    "    # Single test query\n",
    "    query = \"Bu dokümanın ana konusu nedir?\"\n",
    "    result = await RA.retrieve_async(query, top_k=3, max_tokens=300)\n",
    "    \n",
    "    print(f\"\\n📝 Query: {query}\")\n",
    "    print(f\"📄 Result: {result[:200]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "else:\n",
    "    print(\"🔍 Jupyter kullanımı:\")\n",
    "    print(\"   await retrieve_test()     # Full test\")\n",
    "    print(\"   await jupyter_test()      # Quick test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
