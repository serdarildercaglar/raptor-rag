{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e769bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ DOCUMENT CONTENT ANALYSIS:\n",
      "==================================================\n",
      "\n",
      "Result 1 Text Preview:\n",
      "Score: 0.865\n",
      "Type: base\n",
      "Text: Zulficore, kuantum dolanÄ±klÄ±lÄ±k, yapay zekÃ¢ ve frekans tabanlÄ± veri sistemlerini bir araya\n",
      "getirerek; insanlÄ±ÄŸÄ±n bilinÃ§sel evrimini desteklemeyi amaÃ§layan Ã§ok katmanlÄ± bir\n",
      "medeniyet modelidir.\n",
      "Sistem;...\n",
      "Keywords from text: ['zulficore,', 'kuantum', 'dolanÄ±klÄ±lÄ±k,', 'yapay', 'zekÃ¢']\n",
      "\n",
      "Result 2 Text Preview:\n",
      "Score: 0.865\n",
      "Type: reference\n",
      "Text: Zulficore, kuantum dolanÄ±klÄ±lÄ±k, yapay zekÃ¢ ve frekans tabanlÄ± veri sistemlerini bir araya\n",
      "getirerek; insanlÄ±ÄŸÄ±n bilinÃ§sel evrimini desteklemeyi amaÃ§layan Ã§ok katmanlÄ± bir\n",
      "medeniyet modelidir.\n",
      "Sistem;...\n",
      "Keywords from text: ['zulficore,', 'kuantum', 'dolanÄ±klÄ±lÄ±k,', 'yapay', 'zekÃ¢']\n",
      "\n",
      "ðŸ§ª TESTING EXTRACTED KEYWORDS:\n",
      "==================================================\n",
      "'kuantum': 0 results\n",
      "'dolanÄ±klÄ±lÄ±k': 0 results\n",
      "'yapay': 0 results\n",
      "'zekÃ¢': 0 results\n",
      "'frekans': 0 results\n",
      "\n",
      "ðŸŽ¯ TESTING WORKING BATCH QUERIES:\n",
      "==================================================\n",
      "Batch time: 108.6ms\n",
      "\n",
      "1. Zulficore protokolÃ¼ nedir?\n",
      "   Results: 0\n",
      "   âŒ No results\n",
      "\n",
      "2. kuantum dolanÄ±klÄ±lÄ±k nedir?\n",
      "   Results: 0\n",
      "   âŒ No results\n",
      "\n",
      "3. yapay zekÃ¢ sistemi nasÄ±l?\n",
      "   Results: 0\n",
      "   âŒ No results\n",
      "\n",
      "4. frekans tabanlÄ± sistem\n",
      "   Results: 0\n",
      "   âŒ No results\n",
      "\n",
      "5. veri sistemleri nedir?\n",
      "   Results: 0\n",
      "   âŒ No results\n",
      "\n",
      "ðŸ” FUZZY MATCHING TEST:\n",
      "==================================================\n",
      "\n",
      "Testing: 'Zulficore' vs 'query: Zulficore protokolÃ¼'\n",
      "   Short: 0 results (score: 0.000)\n",
      "   Long:  0 results (score: 0.000)\n",
      "\n",
      "Testing: 'protokol' vs 'query: protokol sistemi'\n",
      "   Short: 0 results (score: 0.000)\n",
      "   Long:  0 results (score: 0.000)\n",
      "\n",
      "Testing: 'kuantum' vs 'query: kuantum teknolojisi'\n",
      "   Short: 0 results (score: 0.000)\n",
      "   Long:  0 results (score: 0.000)\n",
      "\n",
      "Testing: 'AI sistem' vs 'query: yapay zeka sistemi'\n",
      "   Short: 0 results (score: 0.000)\n",
      "   Long:  0 results (score: 0.000)\n",
      "\n",
      "Testing: 'frequency' vs 'query: frekans tabanlÄ±'\n",
      "   Short: 0 results (score: 0.000)\n",
      "   Long:  0 results (score: 0.000)\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ CONCLUSION:\n",
      "Batch implementation works fine!\n",
      "Issue is semantic search quality and document coverage.\n",
      "Use more specific, contextual queries for better results.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Better Query Test - Document'te kesin olan terimlerle test\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "\n",
    "def find_working_queries():\n",
    "    \"\"\"Document'te kesin var olan terimleri bul\"\"\"\n",
    "    \n",
    "    # Ã‡alÄ±ÅŸan query'den iÃ§erik al\n",
    "    working_payload = {\n",
    "        \"query\": \"query: Zulficore protokolÃ¼ nedir?\",\n",
    "        \"top_k\": 5\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"http://localhost:8000/retrieve\", json=working_payload)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        \n",
    "        print(\"ðŸ“„ DOCUMENT CONTENT ANALYSIS:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for i, res in enumerate(result['results'][:3], 1):\n",
    "            text = res['text']\n",
    "            print(f\"\\nResult {i} Text Preview:\")\n",
    "            print(f\"Score: {res['score']:.3f}\")\n",
    "            print(f\"Type: {res['node_type']}\")\n",
    "            print(f\"Text: {text[:200]}...\")\n",
    "            \n",
    "            # Extract potential keywords from this text\n",
    "            words = text.lower().split()\n",
    "            common_words = ['ve', 'bir', 'bu', 'iÃ§in', 'ile', 'olan', 'olarak', 'da', 'de', 'den', 'dan', 'ne', 'nasÄ±l', 'nedir']\n",
    "            keywords = [w for w in words if len(w) > 3 and w not in common_words][:10]\n",
    "            print(f\"Keywords from text: {keywords[:5]}\")\n",
    "\n",
    "def test_extracted_keywords():\n",
    "    \"\"\"Extract edilen keyword'lerle test et\"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ§ª TESTING EXTRACTED KEYWORDS:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Document'ten Ã§Ä±kan kesin terimler\n",
    "    document_keywords = [\n",
    "        \"kuantum\",           # quantum'dan \n",
    "        \"dolanÄ±klÄ±lÄ±k\",      # entanglement\n",
    "        \"yapay\",             # artificial\n",
    "        \"zekÃ¢\",              # intelligence  \n",
    "        \"frekans\",           # frequency\n",
    "        \"tabanlÄ±\",           # based\n",
    "        \"veri\",              # data\n",
    "        \"sistem\",            # system\n",
    "        \"Ã¶ÄŸrenme\",           # learning\n",
    "        \"bilinÃ§\"             # consciousness\n",
    "    ]\n",
    "    \n",
    "    # Single query'leri test et\n",
    "    for keyword in document_keywords[:5]:  # Ä°lk 5'i test et\n",
    "        payload = {\n",
    "            \"query\": f\"query: {keyword}\",\n",
    "            \"top_k\": 3,\n",
    "            \"similarity_cutoff\": 0.0\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\"http://localhost:8000/retrieve\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"'{keyword}': {result['total_results']} results\")\n",
    "            if result['total_results'] > 0:\n",
    "                print(f\"   Best score: {result['results'][0]['score']:.3f}\")\n",
    "        else:\n",
    "            print(f\"'{keyword}': ERROR\")\n",
    "\n",
    "def test_working_batch_queries():\n",
    "    \"\"\"Document'te kesin olan terimlerle batch test\"\"\"\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ TESTING WORKING BATCH QUERIES:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Document'te kesin olan/Ã§Ä±kan query pattern'ler\n",
    "    working_queries = [\n",
    "        \"Zulficore protokolÃ¼ nedir?\",      # BildiÄŸimiz Ã§alÄ±ÅŸan\n",
    "        \"kuantum dolanÄ±klÄ±lÄ±k nedir?\",     # Document'te var\n",
    "        \"yapay zekÃ¢ sistemi nasÄ±l?\",       # Document'te var  \n",
    "        \"frekans tabanlÄ± sistem\",          # Document'te var\n",
    "        \"veri sistemleri nedir?\"           # Document'te var\n",
    "    ]\n",
    "    \n",
    "    # Batch test\n",
    "    batch_payload = {\n",
    "        \"queries\": [f\"query: {q}\" for q in working_queries],\n",
    "        \"top_k\": 3,\n",
    "        \"similarity_cutoff\": 0.0\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"http://localhost:8000/retrieve/batch\", json=batch_payload)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"Batch time: {result['retrieval_time_ms']:.1f}ms\")\n",
    "        \n",
    "        for i, (query, results) in enumerate(zip(working_queries, result['results']), 1):\n",
    "            print(f\"\\n{i}. {query}\")\n",
    "            print(f\"   Results: {len(results)}\")\n",
    "            \n",
    "            if len(results) > 0:\n",
    "                print(f\"   Best score: {results[0]['score']:.3f}\")\n",
    "                print(f\"   Text: {results[0]['text'][:80]}...\")\n",
    "            else:\n",
    "                print(\"   âŒ No results\")\n",
    "    else:\n",
    "        print(f\"Batch error: {response.status_code}\")\n",
    "\n",
    "def test_fuzzy_matching():\n",
    "    \"\"\"Fuzzy matching test - yakÄ±n terimler\"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ” FUZZY MATCHING TEST:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    fuzzy_tests = [\n",
    "        (\"Zulficore\", \"query: Zulficore protokolÃ¼\"),  # Tam vs partial\n",
    "        (\"protokol\", \"query: protokol sistemi\"),      # Context ile\n",
    "        (\"kuantum\", \"query: kuantum teknolojisi\"),     # Context ile\n",
    "        (\"AI sistem\", \"query: yapay zeka sistemi\"),   # EN vs TR\n",
    "        (\"frequency\", \"query: frekans tabanlÄ±\")       # EN vs TR\n",
    "    ]\n",
    "    \n",
    "    for short_query, long_query in fuzzy_tests:\n",
    "        print(f\"\\nTesting: '{short_query}' vs '{long_query}'\")\n",
    "        \n",
    "        # Short query\n",
    "        short_payload = {\"query\": f\"query: {short_query}\", \"top_k\": 1, \"similarity_cutoff\": 0.0}\n",
    "        short_response = requests.post(\"http://localhost:8000/retrieve\", json=short_payload)\n",
    "        short_count = 0\n",
    "        short_score = 0\n",
    "        if short_response.status_code == 200:\n",
    "            short_result = short_response.json()\n",
    "            short_count = short_result['total_results']\n",
    "            if short_count > 0:\n",
    "                short_score = short_result['results'][0]['score']\n",
    "        \n",
    "        # Long query  \n",
    "        long_payload = {\"query\": long_query, \"top_k\": 1, \"similarity_cutoff\": 0.0}\n",
    "        long_response = requests.post(\"http://localhost:8000/retrieve\", json=long_payload)\n",
    "        long_count = 0\n",
    "        long_score = 0\n",
    "        if long_response.status_code == 200:\n",
    "            long_result = long_response.json()\n",
    "            long_count = long_result['total_results']\n",
    "            if long_count > 0:\n",
    "                long_score = long_result['results'][0]['score']\n",
    "        \n",
    "        print(f\"   Short: {short_count} results (score: {short_score:.3f})\")\n",
    "        print(f\"   Long:  {long_count} results (score: {long_score:.3f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    find_working_queries()\n",
    "    test_extracted_keywords()\n",
    "    test_working_batch_queries()\n",
    "    test_fuzzy_matching()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“‹ CONCLUSION:\")\n",
    "    print(\"Batch implementation works fine!\")\n",
    "    print(\"Issue is semantic search quality and document coverage.\")\n",
    "    print(\"Use more specific, contextual queries for better results.\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
